<!DOCTYPE html>
<html lang="en">
<head>
	<meta charset="utf-8" />
	<title>Web Audio 2</title>
	<style>
		canvas{border:1px solid black;display:block;}
	</style>
</head>
<body>
<canvas width="640" height="480"></canvas>

<!-- use obama-oilspill.mp3 or human-voice.mp3 -->
<audio controls src="sounds/obama-oilspill.mp3"></audio>

<script>
	const NUM_SAMPLES = 64;
	// 1 - get reference to <audio> element on page
	let audioElement = document.querySelector('audio');
			
	// 2 - create a new `AudioContext` object
	// https://developer.mozilla.org/en-US/docs/Web/API/AudioContext
	let audioCtx = new (window.AudioContext || window.webkitAudioContext); // to support Safari and mobile
	
	// 3 - create a node that points at the <audio> element
	// https://developer.mozilla.org/en-US/docs/Web/API/AudioContext/createMediaElementSource
	let sourceNode = audioCtx.createMediaElementSource(audioElement); 
	
	// 4 - create a *analyser node*
	// https://developer.mozilla.org/en-US/docs/Web/API/AnalyserNode
	// this gets us real-time frequency and time-domain (i.e. waveform) information
	let analyserNode = audioCtx.createAnalyser();
	
	// 5 - How many samples do we want? fft stands for Fast Fourier Transform
	analyserNode.fftSize = NUM_SAMPLES;
	
	// 6 - hook up the <audio> element to the analyserNode
	sourceNode.connect(analyserNode);
	
	// 7 - connect to the destination i.e. the speakers
	analyserNode.connect(audioCtx.destination);
	
	// 8 - create a new array of 8-bit integers (0-255)
	  // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Uint8Array
	  let data = new Uint8Array(analyserNode.frequencyBinCount); // OR analyserNode.fftSize/2
	
	// Chrome autoplay fix
	// https://developers.google.com/web/updates/2017/09/autoplay-policy-changes
	document.querySelector("audio").onplay = (e) => {
  	  if (audioCtx.state == "suspended") {
    	    audioCtx.resume();
  	  }
	};
	
	// canvas stuff
	let ctx = document.querySelector("canvas").getContext("2d");
	const BAR_WIDTH = 30;
	const MAX_BAR_HEIGHT = 100;
	const PADDING = 4;
	const MIDDLE_Y = ctx.canvas.height/2;
	
	
	
	loop();
	
	function loop() { 
	    // 9 - this schedules a call to the loop() method in 1/60 second
	    requestAnimationFrame(loop);
		
	 
		
	    // 10 - populate the array with the frequency data
	    // notice these arrays are passed *by reference*
	    analyserNode.getByteFrequencyData(data);
		
	    // 11 - this time, let's visualize the audio data on the canvas
        ctx.fillStyle = "rgba(0,0,0,0.1)";
        ctx.fillRect(0,0,ctx.canvas.width,ctx.canvas.height);

        // 12 - draw a bar for each frequency bin
        data = data.slice(0,22);

        ctx.save();
        ctx.translate(320,MIDDLE_Y-120); // move to middle of canvas
        for (let b of data) {
            // ctx.fillStyle = `hsl(${b},100%,50%)`;
            ctx.fillStyle = `rgb(${b},${b-128},${255-b})`;
            let percent = b/255;
            if (percent < 0.02) percent = 0.02; // clip at the bottom
            ctx.rotate(2*Math.PI/data.length); // rotate the canvas
            ctx.save();
            ctx.scale(1,-1); // scale the canvas
            ctx.fillRect(0,0,BAR_WIDTH,MAX_BAR_HEIGHT*percent);
            ctx.restore();
            ctx.translate(BAR_WIDTH+PADDING,0); // move over
        }

        ctx.restore();

        // line
        ctx.save();
        ctx.strokeStyle = "white";
        ctx.lineWidth = 3;
        let x = -(ctx.canvas.width/data.length);
        let y = MIDDLE_Y +200;
        ctx.beginPath();
        ctx.moveTo(x,y);
        for(let b of data) {
            ctx.lineTo(x,y-b);
            x += ctx.canvas.width/(data.length-10);
        }
        ctx.stroke();
        ctx.closePath();
        ctx.restore();
        
	}
	
</script>
</body>
</html>